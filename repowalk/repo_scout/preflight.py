"""Stage 1: deterministic pre-pass to gather repo facts."""

from __future__ import annotations

from collections import Counter
from dataclasses import dataclass
import fnmatch
import re
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from .filters import TEXT_EXTENSIONS, should_skip_path
from .schema import BuildSystem, CodegenMarker, RepoFacts, SurfaceSignal


SURFACE_PATTERNS = {
    "cli": {
        "file_patterns": ["cli.py", "cli/*.py", "cmd/**/*.go", "bin/*"],
        "content_patterns": [
            r"argparse\.ArgumentParser",
            r"@click\.(command|group|option)",
            r"cobra\.Command",
            r"clap::(Parser|Command)",
            r"\.command\(|\.option\(",
        ],
    },
    "http": {
        "file_patterns": ["routes/*.py", "handlers/*.go", "controllers/*.java", "api/*.ts"],
        "content_patterns": [
            r"@app\.(route|get|post|put|delete)",
            r"@(Get|Post|Put|Delete)Mapping",
            r"router\.(get|post|put|delete)",
            r"@(api_view|action)",
            r"fastapi|FastAPI",
        ],
    },
    "grpc": {
        "file_patterns": ["**/*.proto", "pb/*.go", "*_grpc.py"],
        "content_patterns": [r"service\s+\w+\s*\{", r"RegisterServer"],
    },
    "plugin": {
        "file_patterns": ["manifest.json", "plugin.xml", "package.json"],
        "content_patterns": [r'"contributes"', r'"extensionPoints"', r"register_hook|add_hook"],
    },
    "public_api": {
        "file_patterns": ["__init__.py", "index.ts", "index.js", "mod.rs", "lib.rs"],
        "content_patterns": [r"__all__\s*=", r"export\s+(default\s+)?\{", r"pub\s+(fn|struct|mod)"],
    },
}

BUILD_SYSTEM_FILES = {
    "package.json": "npm",
    "pyproject.toml": "pip",
    "setup.py": "pip",
    "setup.cfg": "pip",
    "Cargo.toml": "cargo",
    "go.mod": "go",
    "pom.xml": "maven",
    "build.gradle": "gradle",
    "BUILD": "bazel",
    "WORKSPACE": "bazel",
    "CMakeLists.txt": "cmake",
    "Makefile": "make",
    "meson.build": "meson",
}

CODEGEN_PATTERNS = [
    r"DO NOT EDIT",
    r"generated by",
    r"auto-generated",
    r"@generated",
    r"Code generated by",
]

CONVENTIONAL_ENTRIES = {
    "main.py",
    "main.go",
    "main.rs",
    "main.cpp",
    "main.c",
    "index.ts",
    "index.js",
    "app.py",
    "app.ts",
    "app.js",
}

MONOREPO_DIRS = ["packages", "apps", "services", "libs"]


def gather_repo_facts(repo_path: Path) -> RepoFacts:
    """Gather facts about a repository without using an LLM."""
    repo_path = Path(repo_path).resolve()

    file_counts = Counter()
    total_lines = 0
    all_files: List[Path] = []

    for path in repo_path.rglob("*"):
        if should_skip_path(path, repo_path):
            continue
        if path.is_file():
            rel = path.relative_to(repo_path)
            all_files.append(rel)
            file_counts[path.suffix.lower()] += 1
            if path.suffix.lower() in TEXT_EXTENSIONS:
                try:
                    with path.open("rb") as handle:
                        total_lines += sum(1 for _ in handle)
                except OSError:
                    pass

    build_systems = _detect_build_systems(repo_path)
    surface_signals = _detect_surface_signals(repo_path, all_files)
    is_monorepo, packages = _detect_monorepo(repo_path)
    readme_path = _find_readme(repo_path)
    doc_paths = _find_directories(repo_path, ["docs", "doc", "documentation"])
    example_paths = _find_directories(repo_path, ["examples", "example", "tutorials", "samples"])
    codegen_markers = _detect_codegen(repo_path, all_files[:100])
    conventional_entries = _find_conventional_entries(all_files)

    return RepoFacts(
        file_counts_by_extension=dict(file_counts),
        total_files=len(all_files),
        total_lines=total_lines,
        build_systems=build_systems,
        surface_signals=surface_signals,
        is_monorepo=is_monorepo,
        workspace_packages=packages,
        has_readme=readme_path is not None,
        readme_path=readme_path,
        doc_paths=doc_paths,
        example_paths=example_paths,
        codegen_markers=codegen_markers,
        conventional_entries=conventional_entries,
    )


def _detect_build_systems(repo_path: Path) -> List[BuildSystem]:
    build_systems = []
    for filename, kind in BUILD_SYSTEM_FILES.items():
        if (repo_path / filename).exists():
            build_systems.append(BuildSystem(kind=kind, config_file=filename))
    return build_systems


def _detect_surface_signals(repo_path: Path, files: List[Path]) -> List[SurfaceSignal]:
    signals = []

    for surface_kind, patterns in SURFACE_PATTERNS.items():
        locations: List[str] = []
        evidence: List[str] = []

        for file_pattern in patterns.get("file_patterns", []):
            for match in repo_path.glob(file_pattern):
                if should_skip_path(match, repo_path):
                    continue
                locations.append(str(match.relative_to(repo_path)))
                evidence.append(f"file: {file_pattern}")

        content_patterns = patterns.get("content_patterns", [])
        if content_patterns:
            sample_files = _sample_files_for_surface(repo_path, files, surface_kind)
            for rel_path in sample_files[:10]:
                target = repo_path / rel_path
                try:
                    content = target.read_text(errors="replace")[:10000]
                except OSError:
                    continue
                for pattern in content_patterns:
                    if re.search(pattern, content):
                        if str(rel_path) not in locations:
                            locations.append(str(rel_path))
                        evidence.append(f"pattern: {pattern[:30]}")
                        break

        if locations:
            signals.append(
                SurfaceSignal(
                    kind=surface_kind,
                    evidence=", ".join(sorted(set(evidence)))[:100],
                    locations=locations[:10],
                )
            )

    return signals


def _sample_files_for_surface(repo_path: Path, files: List[Path], surface_kind: str) -> List[Path]:
    extensions = {
        "cli": {".py", ".js", ".ts", ".go", ".rs"},
        "http": {".py", ".js", ".ts", ".go", ".java"},
        "grpc": {".proto", ".py", ".go"},
        "plugin": {".json", ".xml", ".py", ".js", ".ts"},
        "public_api": {".py", ".js", ".ts", ".rs"},
    }
    allowed = extensions.get(surface_kind, set())
    return [f for f in files if f.suffix.lower() in allowed]


def _detect_monorepo(repo_path: Path) -> Tuple[bool, List[str]]:
    packages: List[str] = []
    config_files = set(BUILD_SYSTEM_FILES.keys())

    for marker in MONOREPO_DIRS:
        root = repo_path / marker
        if not root.is_dir():
            continue
        for child in root.iterdir():
            if not child.is_dir():
                continue
            if any((child / config).exists() for config in config_files):
                packages.append(str(child.relative_to(repo_path)))

    return (len(packages) >= 2), packages


def _find_readme(repo_path: Path) -> Optional[str]:
    for name in ["README.md", "README.rst", "README.txt", "README"]:
        candidate = repo_path / name
        if candidate.exists():
            return str(candidate.relative_to(repo_path))
    return None


def _find_directories(repo_path: Path, names: List[str]) -> List[str]:
    results: List[str] = []
    for path in repo_path.rglob("*"):
        if should_skip_path(path, repo_path):
            continue
        if path.is_dir() and path.name.lower() in names:
            results.append(str(path.relative_to(repo_path)))
    return results


def _detect_codegen(repo_path: Path, files: List[Path]) -> List[CodegenMarker]:
    markers: List[CodegenMarker] = []
    compiled = [(pattern, re.compile(pattern)) for pattern in CODEGEN_PATTERNS]

    for pattern, regex in compiled:
        matches: List[str] = []
        for rel_path in files:
            target = repo_path / rel_path
            if target.suffix.lower() not in TEXT_EXTENSIONS:
                continue
            try:
                content = target.read_text(errors="replace")[:10000]
            except OSError:
                continue
            if regex.search(content):
                matches.append(str(rel_path))
        if matches:
            markers.append(CodegenMarker(pattern=pattern, files=matches))

    return markers


def _find_conventional_entries(files: List[Path]) -> List[str]:
    entries: List[str] = []
    for rel_path in files:
        if rel_path.name in CONVENTIONAL_ENTRIES:
            entries.append(str(rel_path))
    return entries
